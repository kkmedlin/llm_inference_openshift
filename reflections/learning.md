# Daily Reflection Questions

This file contains questions I ask myself each day while working on this project. 
Iâ€™m using ChatGPT as a learning and guidance tool to reflect on design decisions, implementation, and ML principles.

## Questions

### Project Design
- Why did I choose this model (e.g., distilgpt2) for CPU-only inference?
- How could I improve model efficiency without using a GPU?
- What are the trade-offs of quantization vs distilled models?

### Implementation
- Did I follow best practices for Python, modularity, and code readability?
- Are there any parts of the code I could refactor to be cleaner or more reusable?
- How does caching the model locally affect workflow and performance?

### Benchmarks / Performance
- What patterns do I notice in latency measurements?
- Which runtime (PyTorch, ONNX) seems more efficient for CPU?
- How could I structure benchmarks to be more informative?

### Learning & Reflection
- What new concepts did I learn today about LLM inference or OpenShift?
- How did using ChatGPT help me understand or make decisions today?
- What would I do differently if I started this step over tomorrow?
